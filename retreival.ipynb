{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5d74c302db4f1faf54ae42cce9ae6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pytorch_gpu_env\\lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\USER\\.cache\\huggingface\\hub\\models--BAAI--bge-base-en-v1.5. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06259844d20d409c90fd6a25b5d5b790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc00feabd174a5f89d502d419023444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef6afbf8aeb04982b528523f691bb922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b689ff141c6448f29c539afbfe61c617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/777 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a5c63e248d84019a2164136725fbb9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(text):\n",
    "    \"\"\"Generate embeddings for a given text.\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(**inputs).last_hidden_state.mean(dim=1)\n",
    "    return embeddings.squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(base_folder):\n",
    "    \"\"\"Load judgments and URLs from text files in the base folder.\"\"\"\n",
    "    data = []\n",
    "    for folder_name in os.listdir(base_folder):\n",
    "        folder_path = os.path.join(base_folder, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for file_name in os.listdir(folder_path):\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "                if file_name.endswith(\".txt\"):\n",
    "                    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                        url = file.readline().strip()\n",
    "                        content = file.read().strip()\n",
    "                        data.append({\"url\": url, \"text\": content})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pinecone(api_key=\"pcsk_4b3hm7_NbZGNPRPDSvAoJECCMG93FLyaQM9ZRBTbT8hToBFNsLsJ8baK7gpvEpPwF3P2EA\")\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "pc=Pinecone(api_key=\"pcsk_4b3hm7_NbZGNPRPDSvAoJECCMG93FLyaQM9ZRBTbT8hToBFNsLsJ8baK7gpvEpPwF3P2EA\")\n",
    "index_name = \"judgment-search\"\n",
    "if index_name not in pc.list_indexes():\n",
    "    pc.create_index(index_name, dimension=768 ,spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\")\n",
    "        )  # Adjust dimension based on model\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_in_pinecone(data):\n",
    "    \"\"\"Generate embeddings and store data in Pinecone.\"\"\"\n",
    "    for i, item in enumerate(data):\n",
    "        embedding = generate_embedding(item[\"text\"])\n",
    "        index.upsert([(f\"doc-{i}\", embedding, {\"url\": item[\"url\"], \"text\": item[\"text\"][:200]})])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_pinecone(query_text, top_k=10):\n",
    "    \"\"\"Query Pinecone for similar texts.\"\"\"\n",
    "    # Generate the embedding for the query text\n",
    "    query_embedding = generate_embedding(query_text)\n",
    "    \n",
    "    # Perform the query using keyword arguments\n",
    "    results = index.query(vector=query_embedding.tolist(), top_k=top_k, include_metadata=True)\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1922 judgments.\n",
      "Data stored in Pinecone.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The argument order for `query()` has changed; please use keyword arguments instead of positional arguments. Example: index.query(vector=[0.1, 0.2, 0.3], top_k=10, namespace='my_namespace')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Example query\u001b[39;00m\n\u001b[0;32m     14\u001b[0m query_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample legal judgment text to search for similar cases.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 15\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mquery_pinecone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatches\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScore: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, URL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m, in \u001b[0;36mquery_pinecone\u001b[1;34m(query_text, top_k)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Query Pinecone for similar texts.\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m query_embedding \u001b[38;5;241m=\u001b[39m generate_embedding(query_text)\n\u001b[1;32m----> 4\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32md:\\pytorch_gpu_env\\lib\\site-packages\\pinecone\\utils\\error_handling.py:11\u001b[0m, in \u001b[0;36mvalidate_and_convert_errors.<locals>.inner_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner_func\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 11\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m MaxRetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ProtocolError):\n",
      "File \u001b[1;32md:\\pytorch_gpu_env\\lib\\site-packages\\pinecone\\data\\index.py:406\u001b[0m, in \u001b[0;36mIndex.query\u001b[1;34m(self, top_k, vector, id, namespace, filter, include_values, include_metadata, sparse_vector, *args, **kwargs)\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;124;03mThe Query operation searches a namespace, using a query vector.\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;124;03mIt retrieves the ids of the most similar items in a namespace, along with their similarity scores.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;124;03m         and namespace name.\u001b[39;00m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 406\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    407\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe argument order for `query()` has changed; please use keyword arguments instead of positional arguments. Example: index.query(vector=[0.1, 0.2, 0.3], top_k=10, namespace=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmy_namespace\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    408\u001b[0m     )\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m vector \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot specify both `id` and `vector`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: The argument order for `query()` has changed; please use keyword arguments instead of positional arguments. Example: index.query(vector=[0.1, 0.2, 0.3], top_k=10, namespace='my_namespace')"
     ]
    }
   ],
   "source": [
    "base_folder = \"writ\"\n",
    "# Load data\n",
    "data = load_data(base_folder)\n",
    "print(f\"Loaded {len(data)} judgments.\")\n",
    "\n",
    "    # Store data in Pinecone\n",
    "store_in_pinecone(data)\n",
    "print(\"Data stored in Pinecone.\")\n",
    "\n",
    "#     # Example query\n",
    "# query_text = \"Sample legal judgment text to search for similar cases.\"\n",
    "#     results = query_pinecone(query_text)\n",
    "#     for result in results[\"matches\"]:\n",
    "#         print(f\"Score: {result['score']}, URL: {result['metadata']['url']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.828869224, URL: https://indiankanoon.org/docfragment/953550/?formInput=habeas%20corpus%20%20doctypes%3A%20judgments\n",
      "Score: 0.822812796, URL: https://indiankanoon.org/docfragment/65444816/?formInput=habeas%20corpus%20%20doctypes%3A%20judgments\n",
      "Score: 0.820750475, URL: https://indiankanoon.org/docfragment/161055323/?formInput=habeas%20corpus%20%20doctypes%3A%20judgments\n",
      "Score: 0.817860186, URL: https://indiankanoon.org/docfragment/89846666/?formInput=habeas%20corpus%20%20doctypes%3A%20judgments\n",
      "Score: 0.816762626, URL: https://indiankanoon.org/docfragment/107270237/?formInput=habeas%20corpus%20%20doctypes%3A%20judgments\n",
      "Score: 0.813470066, URL: https://indiankanoon.org/docfragment/884325/?formInput=habeas%20corpus%20%20doctypes%3A%20judgments\n",
      "Score: 0.812360823, URL: https://indiankanoon.org/docfragment/19974910/?formInput=habeas%20corpus%20%20doctypes%3A%20judgments\n",
      "Score: 0.810760796, URL: https://indiankanoon.org/docfragment/14171249/?formInput=habeas%20corpus%20%20doctypes%3A%20judgments\n",
      "Score: 0.810760796, URL: https://indiankanoon.org/docfragment/45976005/?formInput=habeas%20corpus%20%20doctypes%3A%20judgments\n",
      "Score: 0.810760796, URL: https://indiankanoon.org/docfragment/60225137/?formInput=habeas%20corpus%20%20doctypes%3A%20judgments\n"
     ]
    }
   ],
   "source": [
    "query_text = \"A case involving the violation of fundamental rights under Article 21 of the Constitution, where the petitioner seeks the issuance of a writ of habeas corpus for the unlawful detention of an individual.\"\n",
    "results = query_pinecone(query_text,top_k=10)\n",
    "for result in results[\"matches\"]:\n",
    "    print(f\"Score: {result['score']}, URL: {result['metadata']['url']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
